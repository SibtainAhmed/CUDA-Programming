{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMs+f4Z1lsedUa9xPYWLjed",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SibtainAhmed/CUDA-Programming/blob/main/first_CUDA_lab_c%2B%2B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SezxYvK_oKMp",
        "outputId": "02b381e6-8676-47da-9fa0-c4c70f207807"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0rWRrzOoyAS",
        "outputId": "b5dea71f-349e-43c5-b6de-f1b56bddd4f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-sh42w1xn\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-sh42w1xn\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 801584cceb559adc54e828ebe9b385c5f53fe70f\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: nvcc4jupyter\n",
            "  Building wheel for nvcc4jupyter (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvcc4jupyter: filename=nvcc4jupyter-1.2.1-py3-none-any.whl size=10743 sha256=3a570d3ab74e9051a615aa78d54722c78a69a0c83a1d407fccde14c37a30e96c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-knx8joss/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built nvcc4jupyter\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQEZm-XSo-Hu",
        "outputId": "217b5d13-7b12-4caf-d8ce-6e8d89b6c86e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmp2x97uknh\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <iostream>\n",
        "\tint main()\n",
        "{\n",
        "\tstd::cout << \"Welcome To GeeksforGeeks\\n\";\n",
        "\treturn 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXm2cwyNpY5R",
        "outputId": "489c27b8-4be3-4667-9dad-cc11bde01569"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome To GeeksforGeeks\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void hello(){\n",
        "    printf(\"Hello from block: %u, thread: %u\\n\", blockIdx.x, threadIdx.x);\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    hello<<<2, 2>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "    cudaDeviceReset();\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8wRRkgxqlpO",
        "outputId": "9d96962f-0794-4701-b052-dbdefae9cc31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello from block: 1, thread: 0\n",
            "Hello from block: 1, thread: 1\n",
            "Hello from block: 0, thread: 0\n",
            "Hello from block: 0, thread: 1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "\n",
        "#include <stdio.h>\n",
        "#define iter 10\n",
        "\n",
        " __global__ void helloFromGPU()\n",
        " {\n",
        "     printf(\"Salam from GPU; block: %u, thread: %u\\n\", blockIdx.x, threadIdx.x);\n",
        " }\n",
        "\n",
        "int main(){\n",
        "\n",
        "float gpu_elapsed_time_ms, cpu_elapsed_time_ms;\n",
        "cudaEvent_t start, stop;\n",
        "cudaEventCreate(&start);\n",
        "cudaEventCreate(&stop);\n",
        "\n",
        "cudaEventRecord(start, 0);\n",
        "for (int i=0; i<iter; i++)\n",
        "{printf(\"Hello World from CPU!\\n\");}\n",
        "cudaEventRecord(stop, 0);\n",
        "cudaEventSynchronize(stop);\n",
        "cudaEventElapsedTime(&cpu_elapsed_time_ms, start, stop);\n",
        "printf(\"Time elapsed on CPU: %f ms.\\n\\n\", cpu_elapsed_time_ms);\n",
        "\n",
        "\n",
        "cudaEventRecord(start, 0);\n",
        "helloFromGPU<<<1, iter>>>();\n",
        "// time counting terminate\n",
        "cudaEventRecord(stop, 0);\n",
        "cudaEventSynchronize(stop);\n",
        "cudaEventElapsedTime(&gpu_elapsed_time_ms, start, stop);\n",
        "printf(\"Time elapsed on GPU: %f ms.\\n\\n\", gpu_elapsed_time_ms);\n",
        "printf(\"all results are correct!!!\\nUsing threads = %d speedup = %f\\n\",\n",
        "       iter, cpu_elapsed_time_ms / gpu_elapsed_time_ms);\n",
        "\n",
        "cudaDeviceReset();\n",
        "return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHC9zWx_ajPT",
        "outputId": "41b4d197-d420-43e4-9974-6a6307968cd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World from CPU!\n",
            "Hello World from CPU!\n",
            "Hello World from CPU!\n",
            "Hello World from CPU!\n",
            "Hello World from CPU!\n",
            "Hello World from CPU!\n",
            "Hello World from CPU!\n",
            "Hello World from CPU!\n",
            "Hello World from CPU!\n",
            "Hello World from CPU!\n",
            "Time elapsed on CPU: 0.006656 ms.\n",
            "\n",
            "Salam from GPU; block: 0, thread: 0\n",
            "Salam from GPU; block: 0, thread: 1\n",
            "Salam from GPU; block: 0, thread: 2\n",
            "Salam from GPU; block: 0, thread: 3\n",
            "Salam from GPU; block: 0, thread: 4\n",
            "Salam from GPU; block: 0, thread: 5\n",
            "Salam from GPU; block: 0, thread: 6\n",
            "Salam from GPU; block: 0, thread: 7\n",
            "Salam from GPU; block: 0, thread: 8\n",
            "Salam from GPU; block: 0, thread: 9\n",
            "Time elapsed on GPU: 39.812096 ms.\n",
            "\n",
            "all results are correct!!!\n",
            "Using threads = 10 speedup = 0.000167\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void printFromGPU(void)\n",
        "{\n",
        "\n",
        "        printf(\"Hello World from Thread %d %d %d and block %d %d %d \\n\",\n",
        "               threadIdx.x,threadIdx.y,threadIdx.z,\n",
        "               blockIdx.x,blockIdx.y,blockIdx.z);\n",
        "\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "    dim3 grid, block;\n",
        "    grid.x = 2; block.x = 4;\n",
        "    grid.y = 3; block.y = 3;\n",
        "    grid.z = 4; block.z = 2;\n",
        "\n",
        "    printf(\"Salam from CPU \\n\\n\");\n",
        "\n",
        "    printFromGPU<<<grid, block>>>();\n",
        "\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    printf(\"\\n\\nKhuda Hafiz from CPU\\n\\n\");\n",
        "\n",
        "    cudaDeviceReset();\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeLwpaV-oMy2",
        "outputId": "b30666c1-f675-4f06-f562-cbfc4472c77b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Salam from CPU \n",
            "\n",
            "Hello World from Thread 0 0 0 and block 1 0 3 \n",
            "Hello World from Thread 1 0 0 and block 1 0 3 \n",
            "Hello World from Thread 2 0 0 and block 1 0 3 \n",
            "Hello World from Thread 3 0 0 and block 1 0 3 \n",
            "Hello World from Thread 0 1 0 and block 1 0 3 \n",
            "Hello World from Thread 1 1 0 and block 1 0 3 \n",
            "Hello World from Thread 2 1 0 and block 1 0 3 \n",
            "Hello World from Thread 3 1 0 and block 1 0 3 \n",
            "Hello World from Thread 0 2 0 and block 1 0 3 \n",
            "Hello World from Thread 1 2 0 and block 1 0 3 \n",
            "Hello World from Thread 2 2 0 and block 1 0 3 \n",
            "Hello World from Thread 3 2 0 and block 1 0 3 \n",
            "Hello World from Thread 0 0 1 and block 1 0 3 \n",
            "Hello World from Thread 1 0 1 and block 1 0 3 \n",
            "Hello World from Thread 2 0 1 and block 1 0 3 \n",
            "Hello World from Thread 3 0 1 and block 1 0 3 \n",
            "Hello World from Thread 0 1 1 and block 1 0 3 \n",
            "Hello World from Thread 1 1 1 and block 1 0 3 \n",
            "Hello World from Thread 2 1 1 and block 1 0 3 \n",
            "Hello World from Thread 3 1 1 and block 1 0 3 \n",
            "Hello World from Thread 0 2 1 and block 1 0 3 \n",
            "Hello World from Thread 1 2 1 and block 1 0 3 \n",
            "Hello World from Thread 2 2 1 and block 1 0 3 \n",
            "Hello World from Thread 3 2 1 and block 1 0 3 \n",
            "Hello World from Thread 0 0 0 and block 0 1 2 \n",
            "Hello World from Thread 1 0 0 and block 0 1 2 \n",
            "Hello World from Thread 2 0 0 and block 0 1 2 \n",
            "Hello World from Thread 3 0 0 and block 0 1 2 \n",
            "Hello World from Thread 0 1 0 and block 0 1 2 \n",
            "Hello World from Thread 1 1 0 and block 0 1 2 \n",
            "Hello World from Thread 2 1 0 and block 0 1 2 \n",
            "Hello World from Thread 3 1 0 and block 0 1 2 \n",
            "Hello World from Thread 0 2 0 and block 0 1 2 \n",
            "Hello World from Thread 1 2 0 and block 0 1 2 \n",
            "Hello World from Thread 2 2 0 and block 0 1 2 \n",
            "Hello World from Thread 3 2 0 and block 0 1 2 \n",
            "Hello World from Thread 0 0 1 and block 0 1 2 \n",
            "Hello World from Thread 1 0 1 and block 0 1 2 \n",
            "Hello World from Thread 2 0 1 and block 0 1 2 \n",
            "Hello World from Thread 3 0 1 and block 0 1 2 \n",
            "Hello World from Thread 0 1 1 and block 0 1 2 \n",
            "Hello World from Thread 1 1 1 and block 0 1 2 \n",
            "Hello World from Thread 2 1 1 and block 0 1 2 \n",
            "Hello World from Thread 3 1 1 and block 0 1 2 \n",
            "Hello World from Thread 0 2 1 and block 0 1 2 \n",
            "Hello World from Thread 1 2 1 and block 0 1 2 \n",
            "Hello World from Thread 2 2 1 and block 0 1 2 \n",
            "Hello World from Thread 3 2 1 and block 0 1 2 \n",
            "Hello World from Thread 0 0 0 and block 0 2 2 \n",
            "Hello World from Thread 1 0 0 and block 0 2 2 \n",
            "Hello World from Thread 2 0 0 and block 0 2 2 \n",
            "Hello World from Thread 3 0 0 and block 0 2 2 \n",
            "Hello World from Thread 0 1 0 and block 0 2 2 \n",
            "Hello World from Thread 1 1 0 and block 0 2 2 \n",
            "Hello World from Thread 2 1 0 and block 0 2 2 \n",
            "Hello World from Thread 3 1 0 and block 0 2 2 \n",
            "Hello World from Thread 0 2 0 and block 0 2 2 \n",
            "Hello World from Thread 1 2 0 and block 0 2 2 \n",
            "Hello World from Thread 2 2 0 and block 0 2 2 \n",
            "Hello World from Thread 3 2 0 and block 0 2 2 \n",
            "Hello World from Thread 0 0 1 and block 0 2 2 \n",
            "Hello World from Thread 1 0 1 and block 0 2 2 \n",
            "Hello World from Thread 2 0 1 and block 0 2 2 \n",
            "Hello World from Thread 3 0 1 and block 0 2 2 \n",
            "Hello World from Thread 0 1 1 and block 0 2 2 \n",
            "Hello World from Thread 1 1 1 and block 0 2 2 \n",
            "Hello World from Thread 2 1 1 and block 0 2 2 \n",
            "Hello World from Thread 3 1 1 and block 0 2 2 \n",
            "Hello World from Thread 0 2 1 and block 0 2 2 \n",
            "Hello World from Thread 1 2 1 and block 0 2 2 \n",
            "Hello World from Thread 2 2 1 and block 0 2 2 \n",
            "Hello World from Thread 3 2 1 and block 0 2 2 \n",
            "Hello World from Thread 0 0 0 and block 1 2 1 \n",
            "Hello World from Thread 1 0 0 and block 1 2 1 \n",
            "Hello World from Thread 2 0 0 and block 1 2 1 \n",
            "Hello World from Thread 3 0 0 and block 1 2 1 \n",
            "Hello World from Thread 0 1 0 and block 1 2 1 \n",
            "Hello World from Thread 1 1 0 and block 1 2 1 \n",
            "Hello World from Thread 2 1 0 and block 1 2 1 \n",
            "Hello World from Thread 3 1 0 and block 1 2 1 \n",
            "Hello World from Thread 0 2 0 and block 1 2 1 \n",
            "Hello World from Thread 1 2 0 and block 1 2 1 \n",
            "Hello World from Thread 2 2 0 and block 1 2 1 \n",
            "Hello World from Thread 3 2 0 and block 1 2 1 \n",
            "Hello World from Thread 0 0 1 and block 1 2 1 \n",
            "Hello World from Thread 1 0 1 and block 1 2 1 \n",
            "Hello World from Thread 2 0 1 and block 1 2 1 \n",
            "Hello World from Thread 3 0 1 and block 1 2 1 \n",
            "Hello World from Thread 0 1 1 and block 1 2 1 \n",
            "Hello World from Thread 1 1 1 and block 1 2 1 \n",
            "Hello World from Thread 2 1 1 and block 1 2 1 \n",
            "Hello World from Thread 3 1 1 and block 1 2 1 \n",
            "Hello World from Thread 0 2 1 and block 1 2 1 \n",
            "Hello World from Thread 1 2 1 and block 1 2 1 \n",
            "Hello World from Thread 2 2 1 and block 1 2 1 \n",
            "Hello World from Thread 3 2 1 and block 1 2 1 \n",
            "Hello World from Thread 0 0 0 and block 1 1 1 \n",
            "Hello World from Thread 1 0 0 and block 1 1 1 \n",
            "Hello World from Thread 2 0 0 and block 1 1 1 \n",
            "Hello World from Thread 3 0 0 and block 1 1 1 \n",
            "Hello World from Thread 0 1 0 and block 1 1 1 \n",
            "Hello World from Thread 1 1 0 and block 1 1 1 \n",
            "Hello World from Thread 2 1 0 and block 1 1 1 \n",
            "Hello World from Thread 3 1 0 and block 1 1 1 \n",
            "Hello World from Thread 0 2 0 and block 1 1 1 \n",
            "Hello World from Thread 1 2 0 and block 1 1 1 \n",
            "Hello World from Thread 2 2 0 and block 1 1 1 \n",
            "Hello World from Thread 3 2 0 and block 1 1 1 \n",
            "Hello World from Thread 0 0 1 and block 1 1 1 \n",
            "Hello World from Thread 1 0 1 and block 1 1 1 \n",
            "Hello World from Thread 2 0 1 and block 1 1 1 \n",
            "Hello World from Thread 3 0 1 and block 1 1 1 \n",
            "Hello World from Thread 0 1 1 and block 1 1 1 \n",
            "Hello World from Thread 1 1 1 and block 1 1 1 \n",
            "Hello World from Thread 2 1 1 and block 1 1 1 \n",
            "Hello World from Thread 3 1 1 and block 1 1 1 \n",
            "Hello World from Thread 0 2 1 and block 1 1 1 \n",
            "Hello World from Thread 1 2 1 and block 1 1 1 \n",
            "Hello World from Thread 2 2 1 and block 1 1 1 \n",
            "Hello World from Thread 3 2 1 and block 1 1 1 \n",
            "Hello World from Thread 0 0 0 and block 0 0 1 \n",
            "Hello World from Thread 1 0 0 and block 0 0 1 \n",
            "Hello World from Thread 2 0 0 and block 0 0 1 \n",
            "Hello World from Thread 3 0 0 and block 0 0 1 \n",
            "Hello World from Thread 0 1 0 and block 0 0 1 \n",
            "Hello World from Thread 1 1 0 and block 0 0 1 \n",
            "Hello World from Thread 2 1 0 and block 0 0 1 \n",
            "Hello World from Thread 3 1 0 and block 0 0 1 \n",
            "Hello World from Thread 0 2 0 and block 0 0 1 \n",
            "Hello World from Thread 1 2 0 and block 0 0 1 \n",
            "Hello World from Thread 2 2 0 and block 0 0 1 \n",
            "Hello World from Thread 3 2 0 and block 0 0 1 \n",
            "Hello World from Thread 0 0 1 and block 0 0 1 \n",
            "Hello World from Thread 1 0 1 and block 0 0 1 \n",
            "Hello World from Thread 2 0 1 and block 0 0 1 \n",
            "Hello World from Thread 3 0 1 and block 0 0 1 \n",
            "Hello World from Thread 0 1 1 and block 0 0 1 \n",
            "Hello World from Thread 1 1 1 and block 0 0 1 \n",
            "Hello World from Thread 2 1 1 and block 0 0 1 \n",
            "Hello World from Thread 3 1 1 and block 0 0 1 \n",
            "Hello World from Thread 0 2 1 and block 0 0 1 \n",
            "Hello World from Thread 1 2 1 and block 0 0 1 \n",
            "Hello World from Thread 2 2 1 and block 0 0 1 \n",
            "Hello World from Thread 3 2 1 and block 0 0 1 \n",
            "Hello World from Thread 0 0 0 and block 0 2 0 \n",
            "Hello World from Thread 1 0 0 and block 0 2 0 \n",
            "Hello World from Thread 2 0 0 and block 0 2 0 \n",
            "Hello World from Thread 3 0 0 and block 0 2 0 \n",
            "Hello World from Thread 0 1 0 and block 0 2 0 \n",
            "Hello World from Thread 1 1 0 and block 0 2 0 \n",
            "Hello World from Thread 2 1 0 and block 0 2 0 \n",
            "Hello World from Thread 3 1 0 and block 0 2 0 \n",
            "Hello World from Thread 0 2 0 and block 0 2 0 \n",
            "Hello World from Thread 1 2 0 and block 0 2 0 \n",
            "Hello World from Thread 2 2 0 and block 0 2 0 \n",
            "Hello World from Thread 3 2 0 and block 0 2 0 \n",
            "Hello World from Thread 0 0 1 and block 0 2 0 \n",
            "Hello World from Thread 1 0 1 and block 0 2 0 \n",
            "Hello World from Thread 2 0 1 and block 0 2 0 \n",
            "Hello World from Thread 3 0 1 and block 0 2 0 \n",
            "Hello World from Thread 0 1 1 and block 0 2 0 \n",
            "Hello World from Thread 1 1 1 and block 0 2 0 \n",
            "Hello World from Thread 2 1 1 and block 0 2 0 \n",
            "Hello World from Thread 3 1 1 and block 0 2 0 \n",
            "Hello World from Thread 0 2 1 and block 0 2 0 \n",
            "Hello World from Thread 1 2 1 and block 0 2 0 \n",
            "Hello World from Thread 2 2 1 and block 0 2 0 \n",
            "Hello World from Thread 3 2 1 and block 0 2 0 \n",
            "Hello World from Thread 0 0 0 and block 1 0 2 \n",
            "Hello World from Thread 1 0 0 and block 1 0 2 \n",
            "Hello World from Thread 2 0 0 and block 1 0 2 \n",
            "Hello World from Thread 3 0 0 and block 1 0 2 \n",
            "Hello World from Thread 0 1 0 and block 1 0 2 \n",
            "Hello World from Thread 1 1 0 and block 1 0 2 \n",
            "Hello World from Thread 2 1 0 and block 1 0 2 \n",
            "Hello World from Thread 3 1 0 and block 1 0 2 \n",
            "Hello World from Thread 0 2 0 and block 1 0 2 \n",
            "Hello World from Thread 1 2 0 and block 1 0 2 \n",
            "Hello World from Thread 2 2 0 and block 1 0 2 \n",
            "Hello World from Thread 3 2 0 and block 1 0 2 \n",
            "Hello World from Thread 0 0 1 and block 1 0 2 \n",
            "Hello World from Thread 1 0 1 and block 1 0 2 \n",
            "Hello World from Thread 2 0 1 and block 1 0 2 \n",
            "Hello World from Thread 3 0 1 and block 1 0 2 \n",
            "Hello World from Thread 0 1 1 and block 1 0 2 \n",
            "Hello World from Thread 1 1 1 and block 1 0 2 \n",
            "Hello World from Thread 2 1 1 and block 1 0 2 \n",
            "Hello World from Thread 3 1 1 and block 1 0 2 \n",
            "Hello World from Thread 0 2 1 and block 1 0 2 \n",
            "Hello World from Thread 1 2 1 and block 1 0 2 \n",
            "Hello World from Thread 2 2 1 and block 1 0 2 \n",
            "Hello World from Thread 3 2 1 and block 1 0 2 \n",
            "Hello World from Thread 0 0 0 and block 0 0 3 \n",
            "Hello World from Thread 1 0 0 and block 0 0 3 \n",
            "Hello World from Thread 2 0 0 and block 0 0 3 \n",
            "Hello World from Thread 3 0 0 and block 0 0 3 \n",
            "Hello World from Thread 0 1 0 and block 0 0 3 \n",
            "Hello World from Thread 1 1 0 and block 0 0 3 \n",
            "Hello World from Thread 2 1 0 and block 0 0 3 \n",
            "Hello World from Thread 3 1 0 and block 0 0 3 \n",
            "Hello World from Thread 0 2 0 and block 0 0 3 \n",
            "Hello World from Thread 1 2 0 and block 0 0 3 \n",
            "Hello World from Thread 2 2 0 and block 0 0 3 \n",
            "Hello World from Thread 3 2 0 and block 0 0 3 \n",
            "Hello World from Thread 0 0 1 and block 0 0 3 \n",
            "Hello World from Thread 1 0 1 and block 0 0 3 \n",
            "Hello World from Thread 2 0 1 and block 0 0 3 \n",
            "Hello World from Thread 3 0 1 and block 0 0 3 \n",
            "Hello World from Thread 0 1 1 and block 0 0 3 \n",
            "Hello World from Thread 1 1 1 and block 0 0 3 \n",
            "Hello World from Thread 2 1 1 and block 0 0 3 \n",
            "Hello World from Thread 3 1 1 and block 0 0 3 \n",
            "Hello World from Thread 0 2 1 and block 0 0 3 \n",
            "Hello World from Thread 1 2 1 and block 0 0 3 \n",
            "Hello World from Thread 2 2 1 and block 0 0 3 \n",
            "Hello World from Thread 3 2 1 and block 0 0 3 \n",
            "Hello World from Thread 0 0 0 and block 1 0 0 \n",
            "Hello World from Thread 1 0 0 and block 1 0 0 \n",
            "Hello World from Thread 2 0 0 and block 1 0 0 \n",
            "Hello World from Thread 3 0 0 and block 1 0 0 \n",
            "Hello World from Thread 0 1 0 and block 1 0 0 \n",
            "Hello World from Thread 1 1 0 and block 1 0 0 \n",
            "Hello World from Thread 2 1 0 and block 1 0 0 \n",
            "Hello World from Thread 3 1 0 and block 1 0 0 \n",
            "Hello World from Thread 0 2 0 and block 1 0 0 \n",
            "Hello World from Thread 1 2 0 and block 1 0 0 \n",
            "Hello World from Thread 2 2 0 and block 1 0 0 \n",
            "Hello World from Thread 3 2 0 and block 1 0 0 \n",
            "Hello World from Thread 0 0 1 and block 1 0 0 \n",
            "Hello World from Thread 1 0 1 and block 1 0 0 \n",
            "Hello World from Thread 2 0 1 and block 1 0 0 \n",
            "Hello World from Thread 3 0 1 and block 1 0 0 \n",
            "Hello World from Thread 0 1 1 and block 1 0 0 \n",
            "Hello World from Thread 1 1 1 and block 1 0 0 \n",
            "Hello World from Thread 2 1 1 and block 1 0 0 \n",
            "Hello World from Thread 3 1 1 and block 1 0 0 \n",
            "Hello World from Thread 0 2 1 and block 1 0 0 \n",
            "Hello World from Thread 1 2 1 and block 1 0 0 \n",
            "Hello World from Thread 2 2 1 and block 1 0 0 \n",
            "Hello World from Thread 3 2 1 and block 1 0 0 \n",
            "Hello World from Thread 0 0 0 and block 1 1 3 \n",
            "Hello World from Thread 1 0 0 and block 1 1 3 \n",
            "Hello World from Thread 2 0 0 and block 1 1 3 \n",
            "Hello World from Thread 3 0 0 and block 1 1 3 \n",
            "Hello World from Thread 0 1 0 and block 1 1 3 \n",
            "Hello World from Thread 1 1 0 and block 1 1 3 \n",
            "Hello World from Thread 2 1 0 and block 1 1 3 \n",
            "Hello World from Thread 3 1 0 and block 1 1 3 \n",
            "Hello World from Thread 0 2 0 and block 1 1 3 \n",
            "Hello World from Thread 1 2 0 and block 1 1 3 \n",
            "Hello World from Thread 2 2 0 and block 1 1 3 \n",
            "Hello World from Thread 3 2 0 and block 1 1 3 \n",
            "Hello World from Thread 0 0 1 and block 1 1 3 \n",
            "Hello World from Thread 1 0 1 and block 1 1 3 \n",
            "Hello World from Thread 2 0 1 and block 1 1 3 \n",
            "Hello World from Thread 3 0 1 and block 1 1 3 \n",
            "Hello World from Thread 0 1 1 and block 1 1 3 \n",
            "Hello World from Thread 1 1 1 and block 1 1 3 \n",
            "Hello World from Thread 2 1 1 and block 1 1 3 \n",
            "Hello World from Thread 3 1 1 and block 1 1 3 \n",
            "Hello World from Thread 0 2 1 and block 1 1 3 \n",
            "Hello World from Thread 1 2 1 and block 1 1 3 \n",
            "Hello World from Thread 2 2 1 and block 1 1 3 \n",
            "Hello World from Thread 3 2 1 and block 1 1 3 \n",
            "Hello World from Thread 0 0 0 and block 1 2 2 \n",
            "Hello World from Thread 1 0 0 and block 1 2 2 \n",
            "Hello World from Thread 2 0 0 and block 1 2 2 \n",
            "Hello World from Thread 3 0 0 and block 1 2 2 \n",
            "Hello World from Thread 0 1 0 and block 1 2 2 \n",
            "Hello World from Thread 1 1 0 and block 1 2 2 \n",
            "Hello World from Thread 2 1 0 and block 1 2 2 \n",
            "Hello World from Thread 3 1 0 and block 1 2 2 \n",
            "Hello World from Thread 0 2 0 and block 1 2 2 \n",
            "Hello World from Thread 1 2 0 and block 1 2 2 \n",
            "Hello World from Thread 2 2 0 and block 1 2 2 \n",
            "Hello World from Thread 3 2 0 and block 1 2 2 \n",
            "Hello World from Thread 0 0 1 and block 1 2 2 \n",
            "Hello World from Thread 1 0 1 and block 1 2 2 \n",
            "Hello World from Thread 2 0 1 and block 1 2 2 \n",
            "Hello World from Thread 3 0 1 and block 1 2 2 \n",
            "Hello World from Thread 0 1 1 and block 1 2 2 \n",
            "Hello World from Thread 1 1 1 and block 1 2 2 \n",
            "Hello World from Thread 2 1 1 and block 1 2 2 \n",
            "Hello World from Thread 3 1 1 and block 1 2 2 \n",
            "Hello World from Thread 0 2 1 and block 1 2 2 \n",
            "Hello World from Thread 1 2 1 and block 1 2 2 \n",
            "Hello World from Thread 2 2 1 and block 1 2 2 \n",
            "Hello World from Thread 3 2 1 and block 1 2 2 \n",
            "Hello World from Thread 0 0 0 and block 0 0 2 \n",
            "Hello World from Thread 1 0 0 and block 0 0 2 \n",
            "Hello World from Thread 2 0 0 and block 0 0 2 \n",
            "Hello World from Thread 3 0 0 and block 0 0 2 \n",
            "Hello World from Thread 0 1 0 and block 0 0 2 \n",
            "Hello World from Thread 1 1 0 and block 0 0 2 \n",
            "Hello World from Thread 2 1 0 and block 0 0 2 \n",
            "Hello World from Thread 3 1 0 and block 0 0 2 \n",
            "Hello World from Thread 0 2 0 and block 0 0 2 \n",
            "Hello World from Thread 1 2 0 and block 0 0 2 \n",
            "Hello World from Thread 2 2 0 and block 0 0 2 \n",
            "Hello World from Thread 3 2 0 and block 0 0 2 \n",
            "Hello World from Thread 0 0 1 and block 0 0 2 \n",
            "Hello World from Thread 1 0 1 and block 0 0 2 \n",
            "Hello World from Thread 2 0 1 and block 0 0 2 \n",
            "Hello World from Thread 3 0 1 and block 0 0 2 \n",
            "Hello World from Thread 0 1 1 and block 0 0 2 \n",
            "Hello World from Thread 1 1 1 and block 0 0 2 \n",
            "Hello World from Thread 2 1 1 and block 0 0 2 \n",
            "Hello World from Thread 3 1 1 and block 0 0 2 \n",
            "Hello World from Thread 0 2 1 and block 0 0 2 \n",
            "Hello World from Thread 1 2 1 and block 0 0 2 \n",
            "Hello World from Thread 2 2 1 and block 0 0 2 \n",
            "Hello World from Thread 3 2 1 and block 0 0 2 \n",
            "Hello World from Thread 0 0 0 and block 0 1 1 \n",
            "Hello World from Thread 1 0 0 and block 0 1 1 \n",
            "Hello World from Thread 2 0 0 and block 0 1 1 \n",
            "Hello World from Thread 3 0 0 and block 0 1 1 \n",
            "Hello World from Thread 0 1 0 and block 0 1 1 \n",
            "Hello World from Thread 1 1 0 and block 0 1 1 \n",
            "Hello World from Thread 2 1 0 and block 0 1 1 \n",
            "Hello World from Thread 3 1 0 and block 0 1 1 \n",
            "Hello World from Thread 0 2 0 and block 0 1 1 \n",
            "Hello World from Thread 1 2 0 and block 0 1 1 \n",
            "Hello World from Thread 2 2 0 and block 0 1 1 \n",
            "Hello World from Thread 3 2 0 and block 0 1 1 \n",
            "Hello World from Thread 0 0 1 and block 0 1 1 \n",
            "Hello World from Thread 1 0 1 and block 0 1 1 \n",
            "Hello World from Thread 2 0 1 and block 0 1 1 \n",
            "Hello World from Thread 3 0 1 and block 0 1 1 \n",
            "Hello World from Thread 0 1 1 and block 0 1 1 \n",
            "Hello World from Thread 1 1 1 and block 0 1 1 \n",
            "Hello World from Thread 2 1 1 and block 0 1 1 \n",
            "Hello World from Thread 3 1 1 and block 0 1 1 \n",
            "Hello World from Thread 0 2 1 and block 0 1 1 \n",
            "Hello World from Thread 1 2 1 and block 0 1 1 \n",
            "Hello World from Thread 2 2 1 and block 0 1 1 \n",
            "Hello World from Thread 3 2 1 and block 0 1 1 \n",
            "Hello World from Thread 0 0 0 and block 1 0 1 \n",
            "Hello World from Thread 1 0 0 and block 1 0 1 \n",
            "Hello World from Thread 2 0 0 and block 1 0 1 \n",
            "Hello World from Thread 3 0 0 and block 1 0 1 \n",
            "Hello World from Thread 0 1 0 and block 1 0 1 \n",
            "Hello World from Thread 1 1 0 and block 1 0 1 \n",
            "Hello World from Thread 2 1 0 and block 1 0 1 \n",
            "Hello World from Thread 3 1 0 and block 1 0 1 \n",
            "Hello World from Thread 0 2 0 and block 1 0 1 \n",
            "Hello World from Thread 1 2 0 and block 1 0 1 \n",
            "Hello World from Thread 2 2 0 and block 1 0 1 \n",
            "Hello World from Thread 3 2 0 and block 1 0 1 \n",
            "Hello World from Thread 0 0 1 and block 1 0 1 \n",
            "Hello World from Thread 1 0 1 and block 1 0 1 \n",
            "Hello World from Thread 2 0 1 and block 1 0 1 \n",
            "Hello World from Thread 3 0 1 and block 1 0 1 \n",
            "Hello World from Thread 0 1 1 and block 1 0 1 \n",
            "Hello World from Thread 1 1 1 and block 1 0 1 \n",
            "Hello World from Thread 2 1 1 and block 1 0 1 \n",
            "Hello World from Thread 3 1 1 and block 1 0 1 \n",
            "Hello World from Thread 0 2 1 and block 1 0 1 \n",
            "Hello World from Thread 1 2 1 and block 1 0 1 \n",
            "Hello World from Thread 2 2 1 and block 1 0 1 \n",
            "Hello World from Thread 3 2 1 and block 1 0 1 \n",
            "Hello World from Thread 0 0 0 and block 1 1 2 \n",
            "Hello World from Thread 1 0 0 and block 1 1 2 \n",
            "Hello World from Thread 2 0 0 and block 1 1 2 \n",
            "Hello World from Thread 3 0 0 and block 1 1 2 \n",
            "Hello World from Thread 0 1 0 and block 1 1 2 \n",
            "Hello World from Thread 1 1 0 and block 1 1 2 \n",
            "Hello World from Thread 2 1 0 and block 1 1 2 \n",
            "Hello World from Thread 3 1 0 and block 1 1 2 \n",
            "Hello World from Thread 0 2 0 and block 1 1 2 \n",
            "Hello World from Thread 1 2 0 and block 1 1 2 \n",
            "Hello World from Thread 2 2 0 and block 1 1 2 \n",
            "Hello World from Thread 3 2 0 and block 1 1 2 \n",
            "Hello World from Thread 0 0 1 and block 1 1 2 \n",
            "Hello World from Thread 1 0 1 and block 1 1 2 \n",
            "Hello World from Thread 2 0 1 and block 1 1 2 \n",
            "Hello World from Thread 3 0 1 and block 1 1 2 \n",
            "Hello World from Thread 0 1 1 and block 1 1 2 \n",
            "Hello World from Thread 1 1 1 and block 1 1 2 \n",
            "Hello World from Thread 2 1 1 and block 1 1 2 \n",
            "Hello World from Thread 3 1 1 and block 1 1 2 \n",
            "Hello World from Thread 0 2 1 and block 1 1 2 \n",
            "Hello World from Thread 1 2 1 and block 1 1 2 \n",
            "Hello World from Thread 2 2 1 and block 1 1 2 \n",
            "Hello World from Thread 3 2 1 and block 1 1 2 \n",
            "Hello World from Thread 0 0 0 and block 0 2 1 \n",
            "Hello World from Thread 1 0 0 and block 0 2 1 \n",
            "Hello World from Thread 2 0 0 and block 0 2 1 \n",
            "Hello World from Thread 3 0 0 and block 0 2 1 \n",
            "Hello World from Thread 0 1 0 and block 0 2 1 \n",
            "Hello World from Thread 1 1 0 and block 0 2 1 \n",
            "Hello World from Thread 2 1 0 and block 0 2 1 \n",
            "Hello World from Thread 3 1 0 and block 0 2 1 \n",
            "Hello World from Thread 0 2 0 and block 0 2 1 \n",
            "Hello World from Thread 1 2 0 and block 0 2 1 \n",
            "Hello World from Thread 2 2 0 and block 0 2 1 \n",
            "Hello World from Thread 3 2 0 and block 0 2 1 \n",
            "Hello World from Thread 0 0 1 and block 0 2 1 \n",
            "Hello World from Thread 1 0 1 and block 0 2 1 \n",
            "Hello World from Thread 2 0 1 and block 0 2 1 \n",
            "Hello World from Thread 3 0 1 and block 0 2 1 \n",
            "Hello World from Thread 0 1 1 and block 0 2 1 \n",
            "Hello World from Thread 1 1 1 and block 0 2 1 \n",
            "Hello World from Thread 2 1 1 and block 0 2 1 \n",
            "Hello World from Thread 3 1 1 and block 0 2 1 \n",
            "Hello World from Thread 0 2 1 and block 0 2 1 \n",
            "Hello World from Thread 1 2 1 and block 0 2 1 \n",
            "Hello World from Thread 2 2 1 and block 0 2 1 \n",
            "Hello World from Thread 3 2 1 and block 0 2 1 \n",
            "Hello World from Thread 0 0 0 and block 1 1 0 \n",
            "Hello World from Thread 1 0 0 and block 1 1 0 \n",
            "Hello World from Thread 2 0 0 and block 1 1 0 \n",
            "Hello World from Thread 3 0 0 and block 1 1 0 \n",
            "Hello World from Thread 0 1 0 and block 1 1 0 \n",
            "Hello World from Thread 1 1 0 and block 1 1 0 \n",
            "Hello World from Thread 2 1 0 and block 1 1 0 \n",
            "Hello World from Thread 3 1 0 and block 1 1 0 \n",
            "Hello World from Thread 0 2 0 and block 1 1 0 \n",
            "Hello World from Thread 1 2 0 and block 1 1 0 \n",
            "Hello World from Thread 2 2 0 and block 1 1 0 \n",
            "Hello World from Thread 3 2 0 and block 1 1 0 \n",
            "Hello World from Thread 0 0 1 and block 1 1 0 \n",
            "Hello World from Thread 1 0 1 and block 1 1 0 \n",
            "Hello World from Thread 2 0 1 and block 1 1 0 \n",
            "Hello World from Thread 3 0 1 and block 1 1 0 \n",
            "Hello World from Thread 0 1 1 and block 1 1 0 \n",
            "Hello World from Thread 1 1 1 and block 1 1 0 \n",
            "Hello World from Thread 2 1 1 and block 1 1 0 \n",
            "Hello World from Thread 3 1 1 and block 1 1 0 \n",
            "Hello World from Thread 0 2 1 and block 1 1 0 \n",
            "Hello World from Thread 1 2 1 and block 1 1 0 \n",
            "Hello World from Thread 2 2 1 and block 1 1 0 \n",
            "Hello World from Thread 3 2 1 and block 1 1 0 \n",
            "Hello World from Thread 0 0 0 and block 1 2 3 \n",
            "Hello World from Thread 1 0 0 and block 1 2 3 \n",
            "Hello World from Thread 2 0 0 and block 1 2 3 \n",
            "Hello World from Thread 3 0 0 and block 1 2 3 \n",
            "Hello World from Thread 0 1 0 and block 1 2 3 \n",
            "Hello World from Thread 1 1 0 and block 1 2 3 \n",
            "Hello World from Thread 2 1 0 and block 1 2 3 \n",
            "Hello World from Thread 3 1 0 and block 1 2 3 \n",
            "Hello World from Thread 0 2 0 and block 1 2 3 \n",
            "Hello World from Thread 1 2 0 and block 1 2 3 \n",
            "Hello World from Thread 2 2 0 and block 1 2 3 \n",
            "Hello World from Thread 3 2 0 and block 1 2 3 \n",
            "Hello World from Thread 0 0 1 and block 1 2 3 \n",
            "Hello World from Thread 1 0 1 and block 1 2 3 \n",
            "Hello World from Thread 2 0 1 and block 1 2 3 \n",
            "Hello World from Thread 3 0 1 and block 1 2 3 \n",
            "Hello World from Thread 0 1 1 and block 1 2 3 \n",
            "Hello World from Thread 1 1 1 and block 1 2 3 \n",
            "Hello World from Thread 2 1 1 and block 1 2 3 \n",
            "Hello World from Thread 3 1 1 and block 1 2 3 \n",
            "Hello World from Thread 0 2 1 and block 1 2 3 \n",
            "Hello World from Thread 1 2 1 and block 1 2 3 \n",
            "Hello World from Thread 2 2 1 and block 1 2 3 \n",
            "Hello World from Thread 3 2 1 and block 1 2 3 \n",
            "Hello World from Thread 0 0 0 and block 1 2 0 \n",
            "Hello World from Thread 1 0 0 and block 1 2 0 \n",
            "Hello World from Thread 2 0 0 and block 1 2 0 \n",
            "Hello World from Thread 3 0 0 and block 1 2 0 \n",
            "Hello World from Thread 0 1 0 and block 1 2 0 \n",
            "Hello World from Thread 1 1 0 and block 1 2 0 \n",
            "Hello World from Thread 2 1 0 and block 1 2 0 \n",
            "Hello World from Thread 3 1 0 and block 1 2 0 \n",
            "Hello World from Thread 0 2 0 and block 1 2 0 \n",
            "Hello World from Thread 1 2 0 and block 1 2 0 \n",
            "Hello World from Thread 2 2 0 and block 1 2 0 \n",
            "Hello World from Thread 3 2 0 and block 1 2 0 \n",
            "Hello World from Thread 0 0 1 and block 1 2 0 \n",
            "Hello World from Thread 1 0 1 and block 1 2 0 \n",
            "Hello World from Thread 2 0 1 and block 1 2 0 \n",
            "Hello World from Thread 3 0 1 and block 1 2 0 \n",
            "Hello World from Thread 0 1 1 and block 1 2 0 \n",
            "Hello World from Thread 1 1 1 and block 1 2 0 \n",
            "Hello World from Thread 2 1 1 and block 1 2 0 \n",
            "Hello World from Thread 3 1 1 and block 1 2 0 \n",
            "Hello World from Thread 0 2 1 and block 1 2 0 \n",
            "Hello World from Thread 1 2 1 and block 1 2 0 \n",
            "Hello World from Thread 2 2 1 and block 1 2 0 \n",
            "Hello World from Thread 3 2 1 and block 1 2 0 \n",
            "Hello World from Thread 0 0 0 and block 0 1 0 \n",
            "Hello World from Thread 1 0 0 and block 0 1 0 \n",
            "Hello World from Thread 2 0 0 and block 0 1 0 \n",
            "Hello World from Thread 3 0 0 and block 0 1 0 \n",
            "Hello World from Thread 0 1 0 and block 0 1 0 \n",
            "Hello World from Thread 1 1 0 and block 0 1 0 \n",
            "Hello World from Thread 2 1 0 and block 0 1 0 \n",
            "Hello World from Thread 3 1 0 and block 0 1 0 \n",
            "Hello World from Thread 0 2 0 and block 0 1 0 \n",
            "Hello World from Thread 1 2 0 and block 0 1 0 \n",
            "Hello World from Thread 2 2 0 and block 0 1 0 \n",
            "Hello World from Thread 3 2 0 and block 0 1 0 \n",
            "Hello World from Thread 0 0 1 and block 0 1 0 \n",
            "Hello World from Thread 1 0 1 and block 0 1 0 \n",
            "Hello World from Thread 2 0 1 and block 0 1 0 \n",
            "Hello World from Thread 3 0 1 and block 0 1 0 \n",
            "Hello World from Thread 0 1 1 and block 0 1 0 \n",
            "Hello World from Thread 1 1 1 and block 0 1 0 \n",
            "Hello World from Thread 2 1 1 and block 0 1 0 \n",
            "Hello World from Thread 3 1 1 and block 0 1 0 \n",
            "Hello World from Thread 0 2 1 and block 0 1 0 \n",
            "Hello World from Thread 1 2 1 and block 0 1 0 \n",
            "Hello World from Thread 2 2 1 and block 0 1 0 \n",
            "Hello World from Thread 3 2 1 and block 0 1 0 \n",
            "Hello World from Thread 0 0 0 and block 0 2 3 \n",
            "Hello World from Thread 1 0 0 and block 0 2 3 \n",
            "Hello World from Thread 2 0 0 and block 0 2 3 \n",
            "Hello World from Thread 3 0 0 and block 0 2 3 \n",
            "Hello World from Thread 0 1 0 and block 0 2 3 \n",
            "Hello World from Thread 1 1 0 and block 0 2 3 \n",
            "Hello World from Thread 2 1 0 and block 0 2 3 \n",
            "Hello World from Thread 3 1 0 and block 0 2 3 \n",
            "Hello World from Thread 0 2 0 and block 0 2 3 \n",
            "Hello World from Thread 1 2 0 and block 0 2 3 \n",
            "Hello World from Thread 2 2 0 and block 0 2 3 \n",
            "Hello World from Thread 3 2 0 and block 0 2 3 \n",
            "Hello World from Thread 0 0 1 and block 0 2 3 \n",
            "Hello World from Thread 1 0 1 and block 0 2 3 \n",
            "Hello World from Thread 2 0 1 and block 0 2 3 \n",
            "Hello World from Thread 3 0 1 and block 0 2 3 \n",
            "Hello World from Thread 0 1 1 and block 0 2 3 \n",
            "Hello World from Thread 1 1 1 and block 0 2 3 \n",
            "Hello World from Thread 2 1 1 and block 0 2 3 \n",
            "Hello World from Thread 3 1 1 and block 0 2 3 \n",
            "Hello World from Thread 0 2 1 and block 0 2 3 \n",
            "Hello World from Thread 1 2 1 and block 0 2 3 \n",
            "Hello World from Thread 2 2 1 and block 0 2 3 \n",
            "Hello World from Thread 3 2 1 and block 0 2 3 \n",
            "Hello World from Thread 0 0 0 and block 0 0 0 \n",
            "Hello World from Thread 1 0 0 and block 0 0 0 \n",
            "Hello World from Thread 2 0 0 and block 0 0 0 \n",
            "Hello World from Thread 3 0 0 and block 0 0 0 \n",
            "Hello World from Thread 0 1 0 and block 0 0 0 \n",
            "Hello World from Thread 1 1 0 and block 0 0 0 \n",
            "Hello World from Thread 2 1 0 and block 0 0 0 \n",
            "Hello World from Thread 3 1 0 and block 0 0 0 \n",
            "Hello World from Thread 0 2 0 and block 0 0 0 \n",
            "Hello World from Thread 1 2 0 and block 0 0 0 \n",
            "Hello World from Thread 2 2 0 and block 0 0 0 \n",
            "Hello World from Thread 3 2 0 and block 0 0 0 \n",
            "Hello World from Thread 0 0 1 and block 0 0 0 \n",
            "Hello World from Thread 1 0 1 and block 0 0 0 \n",
            "Hello World from Thread 2 0 1 and block 0 0 0 \n",
            "Hello World from Thread 3 0 1 and block 0 0 0 \n",
            "Hello World from Thread 0 1 1 and block 0 0 0 \n",
            "Hello World from Thread 1 1 1 and block 0 0 0 \n",
            "Hello World from Thread 2 1 1 and block 0 0 0 \n",
            "Hello World from Thread 3 1 1 and block 0 0 0 \n",
            "Hello World from Thread 0 2 1 and block 0 0 0 \n",
            "Hello World from Thread 1 2 1 and block 0 0 0 \n",
            "Hello World from Thread 2 2 1 and block 0 0 0 \n",
            "Hello World from Thread 3 2 1 and block 0 0 0 \n",
            "Hello World from Thread 0 0 0 and block 0 1 3 \n",
            "Hello World from Thread 1 0 0 and block 0 1 3 \n",
            "Hello World from Thread 2 0 0 and block 0 1 3 \n",
            "Hello World from Thread 3 0 0 and block 0 1 3 \n",
            "Hello World from Thread 0 1 0 and block 0 1 3 \n",
            "Hello World from Thread 1 1 0 and block 0 1 3 \n",
            "Hello World from Thread 2 1 0 and block 0 1 3 \n",
            "Hello World from Thread 3 1 0 and block 0 1 3 \n",
            "Hello World from Thread 0 2 0 and block 0 1 3 \n",
            "Hello World from Thread 1 2 0 and block 0 1 3 \n",
            "Hello World from Thread 2 2 0 and block 0 1 3 \n",
            "Hello World from Thread 3 2 0 and block 0 1 3 \n",
            "Hello World from Thread 0 0 1 and block 0 1 3 \n",
            "Hello World from Thread 1 0 1 and block 0 1 3 \n",
            "Hello World from Thread 2 0 1 and block 0 1 3 \n",
            "Hello World from Thread 3 0 1 and block 0 1 3 \n",
            "Hello World from Thread 0 1 1 and block 0 1 3 \n",
            "Hello World from Thread 1 1 1 and block 0 1 3 \n",
            "Hello World from Thread 2 1 1 and block 0 1 3 \n",
            "Hello World from Thread 3 1 1 and block 0 1 3 \n",
            "Hello World from Thread 0 2 1 and block 0 1 3 \n",
            "Hello World from Thread 1 2 1 and block 0 1 3 \n",
            "Hello World from Thread 2 2 1 and block 0 1 3 \n",
            "Hello World from Thread 3 2 1 and block 0 1 3 \n",
            "Khuda Hafiz from CPU\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "__global__ void bc(int a) {\n",
        "\n",
        "int laneId = threadIdx.x % warpSize;\n",
        "int warpId = threadIdx.x / warpSize;\n",
        "int value=0;\n",
        "if(warpId==0 && laneId==0){value = a;}\n",
        "printf(\"Warp %d Lane %d: value = %d\\n\", warpId, laneId, value);\n",
        "value = __shfl_sync(0xffffffff, value, 0);\n",
        "printf(\"Warp %d Lane %d: value = %d\\n\", warpId, laneId, value);\n",
        " }\n",
        "\n",
        "int main() {\n",
        "int n=35;\n",
        "bc<<<1,n>>>(1234);\n",
        "cudaDeviceSynchronize();\n",
        "return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bad0vXD8J0rP",
        "outputId": "bfea08a1-1fb7-4c83-8e27-559946ef125c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warp 1 Lane 0: value = 0\n",
            "Warp 1 Lane 1: value = 0\n",
            "Warp 1 Lane 2: value = 0\n",
            "Warp 0 Lane 0: value = 1234\n",
            "Warp 0 Lane 1: value = 0\n",
            "Warp 0 Lane 2: value = 0\n",
            "Warp 0 Lane 3: value = 0\n",
            "Warp 0 Lane 4: value = 0\n",
            "Warp 0 Lane 5: value = 0\n",
            "Warp 0 Lane 6: value = 0\n",
            "Warp 0 Lane 7: value = 0\n",
            "Warp 0 Lane 8: value = 0\n",
            "Warp 0 Lane 9: value = 0\n",
            "Warp 0 Lane 10: value = 0\n",
            "Warp 0 Lane 11: value = 0\n",
            "Warp 0 Lane 12: value = 0\n",
            "Warp 0 Lane 13: value = 0\n",
            "Warp 0 Lane 14: value = 0\n",
            "Warp 0 Lane 15: value = 0\n",
            "Warp 0 Lane 16: value = 0\n",
            "Warp 0 Lane 17: value = 0\n",
            "Warp 0 Lane 18: value = 0\n",
            "Warp 0 Lane 19: value = 0\n",
            "Warp 0 Lane 20: value = 0\n",
            "Warp 0 Lane 21: value = 0\n",
            "Warp 0 Lane 22: value = 0\n",
            "Warp 0 Lane 23: value = 0\n",
            "Warp 0 Lane 24: value = 0\n",
            "Warp 0 Lane 25: value = 0\n",
            "Warp 0 Lane 26: value = 0\n",
            "Warp 0 Lane 27: value = 0\n",
            "Warp 0 Lane 28: value = 0\n",
            "Warp 0 Lane 29: value = 0\n",
            "Warp 0 Lane 30: value = 0\n",
            "Warp 0 Lane 31: value = 0\n",
            "Warp 1 Lane 0: value = 0\n",
            "Warp 1 Lane 1: value = 0\n",
            "Warp 1 Lane 2: value = 0\n",
            "Warp 0 Lane 0: value = 1234\n",
            "Warp 0 Lane 1: value = 1234\n",
            "Warp 0 Lane 2: value = 1234\n",
            "Warp 0 Lane 3: value = 1234\n",
            "Warp 0 Lane 4: value = 1234\n",
            "Warp 0 Lane 5: value = 1234\n",
            "Warp 0 Lane 6: value = 1234\n",
            "Warp 0 Lane 7: value = 1234\n",
            "Warp 0 Lane 8: value = 1234\n",
            "Warp 0 Lane 9: value = 1234\n",
            "Warp 0 Lane 10: value = 1234\n",
            "Warp 0 Lane 11: value = 1234\n",
            "Warp 0 Lane 12: value = 1234\n",
            "Warp 0 Lane 13: value = 1234\n",
            "Warp 0 Lane 14: value = 1234\n",
            "Warp 0 Lane 15: value = 1234\n",
            "Warp 0 Lane 16: value = 1234\n",
            "Warp 0 Lane 17: value = 1234\n",
            "Warp 0 Lane 18: value = 1234\n",
            "Warp 0 Lane 19: value = 1234\n",
            "Warp 0 Lane 20: value = 1234\n",
            "Warp 0 Lane 21: value = 1234\n",
            "Warp 0 Lane 22: value = 1234\n",
            "Warp 0 Lane 23: value = 1234\n",
            "Warp 0 Lane 24: value = 1234\n",
            "Warp 0 Lane 25: value = 1234\n",
            "Warp 0 Lane 26: value = 1234\n",
            "Warp 0 Lane 27: value = 1234\n",
            "Warp 0 Lane 28: value = 1234\n",
            "Warp 0 Lane 29: value = 1234\n",
            "Warp 0 Lane 30: value = 1234\n",
            "Warp 0 Lane 31: value = 1234\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Lab 13"
      ],
      "metadata": {
        "id": "KM-H6E0ACDz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "\n",
        "#include <iostream>\n",
        "#include <chrono>\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "\n",
        "\n",
        "//CUDA kernel\n",
        "__global__ void myKernel(int *result, int N) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < N) {\n",
        "        result[i] = 2 * i;\n",
        "    }\n",
        "}\n",
        "\n",
        "void serialSolution(int *result, int N) {\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        result[i] = 2 * i;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int threads[] = {\n",
        "      1,2,4,8,16\n",
        "    };\n",
        "    for(int i = 0; i < 5; ++i) {\n",
        "      int N = threads[i];\n",
        "    int *result_serial = new int[N];\n",
        "    int *result_cuda;\n",
        "    int size = N * sizeof(int);\n",
        "\n",
        "    cudaMalloc(&result_cuda, size);\n",
        "\n",
        "    auto start = std::chrono::high_resolution_clock::now();\n",
        "    serialSolution(result_serial, N);\n",
        "    auto end = std::chrono::high_resolution_clock::now();\n",
        "    std::chrono::duration<double> serial_duration = end - start;\n",
        "\n",
        "    dim3 blocksPerGrid(1, 1, 1);\n",
        "    dim3 threadsPerBlock( N, 1, 1);\n",
        "\n",
        "    cudaEvent_t start_cuda, stop_cuda;\n",
        "    cudaEventCreate(&start_cuda);\n",
        "    cudaEventCreate(&stop_cuda);\n",
        "\n",
        "    cudaEventRecord(start_cuda);\n",
        "    myKernel<<<blocksPerGrid, threadsPerBlock>>>(result_cuda, N);\n",
        "    cudaEventRecord(stop_cuda);\n",
        "\n",
        "    cudaEventSynchronize(stop_cuda);\n",
        "    float cuda_duration = 0;\n",
        "    cudaEventElapsedTime(&cuda_duration, start_cuda, stop_cuda);\n",
        "\n",
        "    int *result_from_cuda = new int[N];\n",
        "    cudaMemcpy(result_from_cuda, result_cuda, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    double speedup = serial_duration.count() / (cuda_duration / 1000.0);\n",
        "\n",
        "    std::cout << \"For number of threads =\" << N << \" \\n\";\n",
        "    std::cout << \"Serial Execution Time: \" << serial_duration.count() << \" seconds\\n\";\n",
        "    printf(\"CUDA Execution Time using 1 thread blocks & %d threads: %f seconds\\n\", N,\n",
        "           cuda_duration / 1000.0 );\n",
        "    std::cout << \"Speedup: \" << speedup << \"\\n\\n\";\n",
        "\n",
        "\n",
        "    delete[] result_serial;\n",
        "    delete[] result_from_cuda;\n",
        "    cudaFree(result_cuda);\n",
        "    cudaEventDestroy(start_cuda);\n",
        "    cudaEventDestroy(stop_cuda);\n",
        "\n",
        "    }\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CR4qoJ_hCLd_",
        "outputId": "872b3f96-6243-4f99-fb05-8cb35e27ec5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For number of threads =1 \n",
            "Serial Execution Time: 2.15e-07 seconds\n",
            "CUDA Execution Time using 1 thread blocks & 1 threads: 0.000154 seconds\n",
            "Speedup: 0.00139191\n",
            "\n",
            "For number of threads =2 \n",
            "Serial Execution Time: 8.7e-08 seconds\n",
            "CUDA Execution Time using 1 thread blocks & 2 threads: 0.000012 seconds\n",
            "Speedup: 0.00706169\n",
            "\n",
            "For number of threads =4 \n",
            "Serial Execution Time: 8.3e-08 seconds\n",
            "CUDA Execution Time using 1 thread blocks & 4 threads: 0.000009 seconds\n",
            "Speedup: 0.00913292\n",
            "\n",
            "For number of threads =8 \n",
            "Serial Execution Time: 1.33e-07 seconds\n",
            "CUDA Execution Time using 1 thread blocks & 8 threads: 0.000011 seconds\n",
            "Speedup: 0.0121528\n",
            "\n",
            "For number of threads =16 \n",
            "Serial Execution Time: 1.54e-07 seconds\n",
            "CUDA Execution Time using 1 thread blocks & 16 threads: 0.000010 seconds\n",
            "Speedup: 0.0158306\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "\n",
        "#include <iostream>\n",
        "#include <chrono>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define N 512\n",
        "\n",
        "__global__ void matrixAdd(float a[N][N], float b[N][N], float c[N][N]) {\n",
        "    int j = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int i = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    if (i < N && j < N) {\n",
        "        c[i][j] = a[i][j] + b[i][j];\n",
        "    }\n",
        "}\n",
        "__global__ void matrixAdd2(float a[N][N], float b[N][N], float c[N][N]) {\n",
        "    int j = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int i = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    if (i < N && j < N) {\n",
        "        c[i][j] = a[i][j] + b[i][j];\n",
        "    }\n",
        "}\n",
        "\n",
        "void serialMatrixAdd(float a[N][N], float b[N][N], float c[N][N]) {\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int j = 0; j < N; ++j) {\n",
        "            c[i][j] = a[i][j] + b[i][j];\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    float a[N][N], b[N][N], c_serial[N][N], c_cuda[N][N], c_cuda_single_block[N][N];\n",
        "    float (*d_a)[N], (*d_b)[N], (*d_c)[N];\n",
        "\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int j = 0; j < N; ++j) {\n",
        "            a[i][j] = static_cast<float>(i + j);\n",
        "            b[i][j] = static_cast<float>(i - j);\n",
        "        }\n",
        "    }\n",
        "\n",
        "    cudaMalloc((void**)&d_a, N * N * sizeof(float));\n",
        "    cudaMalloc((void**)&d_b, N * N * sizeof(float));\n",
        "    cudaMalloc((void**)&d_c, N * N * sizeof(float));\n",
        "\n",
        "    cudaMemcpy(d_a, a, N * N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, b, N * N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "\n",
        "    auto start = std::chrono::high_resolution_clock::now();\n",
        "    serialMatrixAdd(a, b, c_serial);\n",
        "    auto end = std::chrono::high_resolution_clock::now();\n",
        "    std::chrono::duration<double> serial_duration = end - start;\n",
        "\n",
        "     dim3 blocksPerGrid(N / 2, N / 2, 1);\n",
        "     dim3 threadsPerBlock(2, 2, 1);\n",
        "    //dim3 blocksPerGrid(1, 1, 1);\n",
        "    //dim3 threadsPerBlock(N, N, 1);\n",
        "\n",
        "    cudaEvent_t start_cuda, stop_cuda;\n",
        "    cudaEventCreate(&start_cuda);\n",
        "    cudaEventCreate(&stop_cuda);\n",
        "\n",
        "    cudaEventRecord(start_cuda);\n",
        "    matrixAdd<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c);\n",
        "    cudaEventRecord(stop_cuda);\n",
        "\n",
        "    cudaEventSynchronize(stop_cuda);\n",
        "    float cuda_duration_2x2 = 0;\n",
        "    cudaEventElapsedTime(&cuda_duration_2x2, start_cuda, stop_cuda);\n",
        "\n",
        "\n",
        "    cudaMemcpy(c_cuda, d_c, N * N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // single block\n",
        "    dim3 blocksPerGrid_single(1, 1, 1);\n",
        "    dim3 threadsPerBlock_single(N, N, 1);\n",
        "\n",
        "    cudaEventRecord(start_cuda);\n",
        "    matrixAdd2<<<blocksPerGrid_single, threadsPerBlock_single>>>(d_a, d_b, d_c);\n",
        "    cudaEventRecord(stop_cuda);\n",
        "\n",
        "    cudaEventSynchronize(stop_cuda);\n",
        "    float cuda_duration_single_block = 0;\n",
        "    cudaEventElapsedTime(&cuda_duration_single_block, start_cuda, stop_cuda);\n",
        "\n",
        "\n",
        "    cudaMemcpy(c_cuda_single_block, d_c, N * N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "\n",
        "    double speedup_2x2 = serial_duration.count() / (cuda_duration_2x2 / 1000.0);\n",
        "    double speedup_single_block = serial_duration.count() / (cuda_duration_single_block / 1000.0);\n",
        "    double relative_speedup = (cuda_duration_single_block / 1000.0) / (cuda_duration_2x2 / 1000.0);\n",
        "\n",
        "\n",
        "    std::cout << \"Serial Execution Time: \" << serial_duration.count() << \" seconds\\n\";\n",
        "    std::cout << \"CUDA Execution Time (2x2 blocks): \" << cuda_duration_2x2 / 1000.0 << \" seconds\\n\";\n",
        "    std::cout << \"CUDA Execution Time (single block): \" << cuda_duration_single_block / 1000.0 << \" seconds\\n\";\n",
        "    std::cout << \"Speedup (2x2 blocks): \" << speedup_2x2 << \"\\n\";\n",
        "    std::cout << \"Speedup (single block): \" << speedup_single_block << \"\\n\";\n",
        "    std::cout << \"Relative Speedup (2x2 blocks over single block): \" << relative_speedup << \"\\n\";\n",
        "\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "    cudaEventDestroy(start_cuda);\n",
        "    cudaEventDestroy(stop_cuda);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqsrP97-OoSo",
        "outputId": "13e7853c-37aa-47f0-a1ec-fc8431c7d9e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Serial Execution Time: 0.00071502 seconds\n",
            "CUDA Execution Time (2x2 blocks): 0.00042848 seconds\n",
            "CUDA Execution Time (single block): 1.8304e-05 seconds\n",
            "Speedup (2x2 blocks): 1.66874\n",
            "Speedup (single block): 39.0636\n",
            "Relative Speedup (2x2 blocks over single block): 0.0427184\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### lab 13 task c"
      ],
      "metadata": {
        "id": "uTwOiVf0W7uG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "\n",
        "#include <iostream>\n",
        "#include <chrono>\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define Width 4\n",
        "# define TILE_WIDTH 2\n",
        "\n",
        "__global__ void MatrixMulKernel(int *Md, int *Nd, int *Pd) {\n",
        "// Calculate the row index of the Pd element and M\n",
        "int Row = blockIdx.y*TILE_WIDTH +threadIdx.y;\n",
        "// Calculate the column index of Pd and N\n",
        "int Col = blockIdx.x*TILE_WIDTH + threadIdx.x;\n",
        "float Pvalue = 0;\n",
        "// each thread computes one element of the block sub-matrix\n",
        "for ( int k = 0; k<Width; ++k)\n",
        "{Pvalue += Md[Row*Width+k] * Nd[k*Width+Col]; }\n",
        "Pd[Row*Width+Col] = Pvalue;\n",
        "}\n",
        "\n",
        "\n",
        "void MatrixMulOnHost(int *M, int *N, int *P) {\n",
        "for (int i = 0; i < Width; ++i)\n",
        "for (int j = 0; j < Width; ++j) {\n",
        "int sum = 0;\n",
        "for (int k = 0; k < Width; ++k) {\n",
        "int a = M[i * Width + k];\n",
        "int b = N[k * Width + j];\n",
        "sum += a * b;\n",
        "}\n",
        "P[i * Width + j] = sum;\n",
        "}\n",
        "}\n",
        "\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "int size = Width * Width * sizeof(int);\n",
        "int *h_a, *h_b, *h_c, *h_cc;\n",
        "cudaMallocHost((void **) &h_a, size);\n",
        "cudaMallocHost((void **) &h_b, size);\n",
        "cudaMallocHost((void **) &h_c, size);\n",
        "cudaMallocHost((void **) &h_cc, size);\n",
        "int *Md, *Nd, *Pd;\n",
        "for (int i = 0; i < Width; ++i) {\n",
        "for (int j = 0; j < Width; ++j) {\n",
        "h_a[i * Width + j] = i+j;\n",
        "h_b[i * Width + j] = i+j;\n",
        "}\n",
        "}\n",
        "  cudaMalloc(&Md, size);\n",
        "cudaMemcpy(Md, h_a, size, cudaMemcpyHostToDevice);\n",
        "cudaMalloc(&Nd, size);\n",
        "cudaMemcpy(Nd, h_b, size, cudaMemcpyHostToDevice);\n",
        "// Allocate P on the device\n",
        "cudaMalloc(&Pd, size);\n",
        "float gpu_elapsed_time_ms, cpu_elapsed_time_ms;\n",
        "cudaEvent_t start, stop;\n",
        "cudaEventCreate(&start);\n",
        "cudaEventCreate(&stop);\n",
        "\n",
        "// start the CPU version\n",
        "cudaEventRecord(start, 0);\n",
        "MatrixMulOnHost(h_a,h_b,h_c);\n",
        "cudaEventRecord(stop, 0);\n",
        "cudaEventSynchronize(stop);\n",
        "cudaEventElapsedTime(&cpu_elapsed_time_ms, start, stop);\n",
        "  /*\n",
        "printf(\"Host results\\n\");\n",
        "for (int i = 0; i < Width; ++i) {\n",
        "\n",
        "for (int j = 0; j < Width; ++j) {\n",
        "printf(\"result[%d][%d]=%d\\n\",i,j,h_c[i * Width + j]);\n",
        "}\n",
        "}*/\n",
        "\n",
        "dim3 dimGrid(Width/TILE_WIDTH,Width/TILE_WIDTH);\n",
        "dim3 dimBlock(TILE_WIDTH, TILE_WIDTH);\n",
        "// Launch the device computation threads!\n",
        "cudaEventRecord(start, 0);\n",
        "MatrixMulKernel<<<dimGrid, dimBlock>>>(Md,Nd,Pd);\n",
        "cudaEventRecord(stop, 0);\n",
        "cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&gpu_elapsed_time_ms, start, stop);\n",
        "cudaMemcpy(h_cc, Pd, size, cudaMemcpyDeviceToHost);\n",
        "  /*\n",
        "printf(\"gpu results\\n\");\n",
        "for (int i = 0; i < Width; ++i) {\n",
        "for (int j = 0; j < Width; ++j) {\n",
        "printf(\"result[%d][%d]=%d\\n\",i,j,h_cc[i * Width + j]);\n",
        "}\n",
        " }*/\n",
        "\n",
        "    double speedup = cpu_elapsed_time_ms / gpu_elapsed_time_ms;\n",
        "\n",
        "\n",
        "  std::cout << \"Serial Execution Time: \" << cpu_elapsed_time_ms << \" ms\\n\";\n",
        "  printf(\"for Grid dimension (%d, %d) and block dimension (%d, %d) \\n\",\n",
        "         Width/TILE_WIDTH,Width/TILE_WIDTH,TILE_WIDTH, TILE_WIDTH);\n",
        "    printf(\"CUDA Execution Time: %f ms\\n\"\n",
        "    ,gpu_elapsed_time_ms);\n",
        "    std::cout << \"Speedup: \" << speedup << \"\\n\\n\";\n",
        "\n",
        "    cudaFree(Md); cudaFree(Nd); cudaFree (Pd);\n",
        "\n",
        "return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2ErYHnaTTYq",
        "outputId": "d915d5f7-ae05-4c0a-d5a1-91f26d81dc25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Serial Execution Time: 0.003296 ms\n",
            "for Grid dimension (1, 1) and block dimension (4, 4) \n",
            "CUDA Execution Time: 39.194626 ms\n",
            "Speedup: 8.40932e-05\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CEA**"
      ],
      "metadata": {
        "id": "obxywGrzYUY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "\n",
        "#include <iostream>\n",
        "#include <chrono>\n",
        "#include <stdio.h>\n",
        "#include <iomanip>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "__global__ void convolutionKernel(int* d_inputImage, int* d_kernel, int* d_outputImage) {\n",
        "     int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    //int i =threadIdx.x;\n",
        "    //int j = blockIdx.x;\n",
        "     if (i >= 1 && i < 5) {\n",
        "        for (int j = 1; j < 5; j++) {\n",
        "            int R1 = 0;\n",
        "            for (int k = -1; k < 2; k++) {\n",
        "                for (int m = -1; m < 2; m++) {\n",
        "                    R1 += d_inputImage[(i + k) * 6 + (j + m)] * d_kernel[(k + 1) * 3 + (m + 1)];\n",
        "                }\n",
        "            }\n",
        "            d_outputImage[i * 6 + j] = R1;\n",
        "        }\n",
        "   }\n",
        "}\n",
        "\n",
        "void convolutionSerial(int inputImage[6][6], int kernel[3][3], int outputImage[6][6]) {\n",
        "    for (int i = 1; i < 6-1; i++) {\n",
        "        for (int j = 1; j < 6-1; j++) {\n",
        "            int R1 = 0;\n",
        "            for (int k = -1; k < 2; k++) {\n",
        "                for (int m = -1; m < 2; m++) {\n",
        "                    R1 += inputImage[i + k][j + m] * kernel[k + 1][m + 1];\n",
        "                }\n",
        "            }\n",
        "            outputImage[i][j] = R1;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int inputImage[6][6] = {\n",
        "        {1, 2, 3, 4, 5, 6},\n",
        "        {7, 8, 9, 10, 11, 12},\n",
        "        {13, 14, 15, 16, 17, 18},\n",
        "        {19, 20, 21, 22, 23, 24},\n",
        "        {25, 26, 27, 28, 29, 30},\n",
        "        {31, 32, 33, 34, 35, 36}\n",
        "    };\n",
        "\n",
        "    int kernel[3][3] = {\n",
        "        {3, 4, 5},\n",
        "        {6, 7, 8},\n",
        "        {9, 10, 11}\n",
        "    };\n",
        "\n",
        "    int outputImageSerial[6][6] = {0};\n",
        "    int outputImageParallel[6][6] = {0};\n",
        "\n",
        "    // Serial execution\n",
        "    auto startSerial = chrono::high_resolution_clock::now();\n",
        "    convolutionSerial(inputImage, kernel, outputImageSerial);\n",
        "    auto endSerial = chrono::high_resolution_clock::now();\n",
        "    chrono::duration<double> elapsedSerial = endSerial - startSerial;\n",
        "\n",
        "    int *d_inputImage, *d_kernel, *d_outputImage;\n",
        "    cudaMalloc((void**)&d_inputImage, 6 * 6 * sizeof(int));\n",
        "    cudaMalloc((void**)&d_kernel, 3 * 3 * sizeof(int));\n",
        "    cudaMalloc((void**)&d_outputImage, 6 * 6 * sizeof(int));\n",
        "\n",
        "    cudaMemcpy(d_inputImage, inputImage, 6 * 6 * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_kernel, kernel, 3 * 3 * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Parallel Execution\n",
        "    int num_blocks = 1;\n",
        "    int num_threads = 6;\n",
        "    auto startParallel = chrono::high_resolution_clock::now();\n",
        "    convolutionKernel<<<num_blocks, num_threads>>>(d_inputImage, d_kernel, d_outputImage);\n",
        "    cudaDeviceSynchronize();\n",
        "    auto endParallel = chrono::high_resolution_clock::now();\n",
        "    chrono::duration<double> elapsedParallel = endParallel - startParallel;\n",
        "\n",
        "    cudaMemcpy(outputImageParallel, d_outputImage, 6 * 6 * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "\n",
        "\n",
        "    cout << \"\\n\\nOutput Image from Device:\" << endl;\n",
        "    for (int i = 0; i < 6; i++) {\n",
        "        printf(\"\\n\\t| \");\n",
        "        for (int j = 0; j < 6; j++) {\n",
        "            cout << setw(5) << outputImageParallel[i][j] << \" \";\n",
        "            printf(\"|\");\n",
        "        }\n",
        "        cout << endl;\n",
        "    }\n",
        "\n",
        "\n",
        "    cudaFree(d_inputImage);\n",
        "    cudaFree(d_kernel);\n",
        "    cudaFree(d_outputImage);\n",
        "\n",
        "    double speedup = elapsedSerial.count() / elapsedParallel.count();\n",
        "    double efficiency = speedup / 6;\n",
        "    double cost = elapsedParallel.count() * 6;  //num of block currently = 6\n",
        "\n",
        "    printf(\"\\nSerial Execution time: %fs \\n\", elapsedSerial.count());\n",
        "    printf(\"Parallel Execution time with %d block & %d thread: %fs \\n\", num_blocks, num_threads, elapsedParallel.count());\n",
        "    printf(\"Speedup: %f \\n\", speedup);\n",
        "    printf(\"Efficiency: %f \\n\", efficiency);\n",
        "    printf(\"Cost: %f \\n\", cost);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8BL4CF_Yacb",
        "outputId": "f18bcc20-2cc1-4175-93ee-b127f5c62edd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Output Image from Device:\n",
            "\n",
            "\t|     0 |    0 |    0 |    0 |    0 |    0 |\n",
            "\n",
            "\t|     0 |  618 |  681 |  744 |  807 |    0 |\n",
            "\n",
            "\t|     0 |  996 | 1059 | 1122 | 1185 |    0 |\n",
            "\n",
            "\t|     0 | 1374 | 1437 | 1500 | 1563 |    0 |\n",
            "\n",
            "\t|     0 | 1752 | 1815 | 1878 | 1941 |    0 |\n",
            "\n",
            "\t|     0 |    0 |    0 |    0 |    0 |    0 |\n",
            "\n",
            "Serial Execution time: 0.000001s \n",
            "Parallel Execution time with 1 block & 6 thread: 0.042532s \n",
            "Speedup: 0.000020 \n",
            "Efficiency: 0.000003 \n",
            "Cost: 0.255191 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lab 12"
      ],
      "metadata": {
        "id": "zI5uQflNfWaH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1"
      ],
      "metadata": {
        "id": "j63cd96Ifafi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "\n",
        "#include <iostream>\n",
        "#include <chrono>\n",
        "#include <stdio.h>\n",
        "#include <iomanip>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "// CUDA kernel for addition\n",
        "__global__ void addKernel(float* a, float* b, float* c, int size) {\n",
        "    int idx = threadIdx.x;\n",
        "    if (idx < size) {\n",
        "        c[idx] = a[idx] + b[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "// CUDA kernel for subtraction\n",
        "__global__ void subKernel(float* a, float* b, float* c, int size) {\n",
        "    int idx = threadIdx.x;\n",
        "    if (idx < size) {\n",
        "        c[idx] = a[idx] - b[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "// CUDA kernel for multiplication\n",
        "__global__ void mulKernel(float* a, float* b, float* c, int size) {\n",
        "    int idx = threadIdx.x;\n",
        "    if (idx < size) {\n",
        "        c[idx] = a[idx] * b[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "// CUDA kernel for division\n",
        "__global__ void divKernel(float* a, float* b, float* c, int size) {\n",
        "    int idx = threadIdx.x;\n",
        "    if (idx < size) {\n",
        "        c[idx] = a[idx] / b[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "// Serial implementation for addition\n",
        "void addSerial(float* a, float* b, float* c, int size) {\n",
        "    for (int i = 0; i < size; ++i) {\n",
        "        c[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "// Serial implementation for subtraction\n",
        "void subSerial(float* a, float* b, float* c, int size) {\n",
        "    for (int i = 0; i < size; ++i) {\n",
        "        c[i] = a[i] - b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "// Serial implementation for multiplication\n",
        "void mulSerial(float* a, float* b, float* c, int size) {\n",
        "    for (int i = 0; i < size; ++i) {\n",
        "        c[i] = a[i] * b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "// Serial implementation for division\n",
        "void divSerial(float* a, float* b, float* c, int size) {\n",
        "    for (int i = 0; i < size; ++i) {\n",
        "        c[i] = a[i] / b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "// Function to generate random float array\n",
        "void generateRandomArray(float* arr, int size) {\n",
        "    for (int i = 0; i < size; ++i) {\n",
        "        arr[i] = static_cast<float>(rand()) / RAND_MAX;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int sizes[] = {50, 100, 500};\n",
        "\n",
        "    for (int s = 0; s < 3; s++) {\n",
        "        int size = sizes[s];\n",
        "        float* h_a = new float[size];\n",
        "        float* h_b = new float[size];\n",
        "        float* h_c = new float[size];\n",
        "        float *d_a, *d_b, *d_c;\n",
        "\n",
        "        generateRandomArray(h_a, size);\n",
        "        generateRandomArray(h_b, size);\n",
        "\n",
        "        cudaMalloc(&d_a, size * sizeof(float));\n",
        "        cudaMalloc(&d_b, size * sizeof(float));\n",
        "        cudaMalloc(&d_c, size * sizeof(float));\n",
        "\n",
        "        cudaMemcpy(d_a, h_a, size * sizeof(float), cudaMemcpyHostToDevice);\n",
        "        cudaMemcpy(d_b, h_b, size * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "        // Measure time for CUDA addition\n",
        "            auto startParallel = chrono::high_resolution_clock::now();\n",
        "\n",
        "        divKernel<<<1, size>>>(d_a, d_b, d_c, size);\n",
        "\n",
        "\n",
        "    auto endParallel = chrono::high_resolution_clock::now();\n",
        "    chrono::duration<double> gpu_time = endParallel - startParallel;\n",
        "\n",
        "      printf(\"CUDA addition time for size %d: %f\\n\", size, gpu_time);\n",
        "//        cout << \"CUDA addition time for size \" << size << \": \" << gpu_time << \" s\\n\";\n",
        "\n",
        "        // Measure time for serial addition\n",
        "            auto startSerial = chrono::high_resolution_clock::now();\n",
        "\n",
        "\n",
        "        mulSerial(h_a, h_b, h_c, size);\n",
        "\n",
        "\n",
        "    auto endSerial = chrono::high_resolution_clock::now();\n",
        "    chrono::duration<double> cpu_time = endSerial - startSerial;\n",
        "              printf(\"CPU multiplication time for size %d: %f\\n\", size, cpu_time);\n",
        "\n",
        "//        std::cout << \"CPU multiplication time for size \" << size << \": \" << cpu_time << \" s\\n\";\n",
        "\n",
        "        // Compute speedup\n",
        "        float speedup = cpu_time / (gpu_time);  // converting ms to s\n",
        "        std::cout << \"Speedup for size \" << size << \": \" << speedup << \"\\n\\n\";\n",
        "\n",
        "        // Repeat similar steps for subtraction, multiplication, and division\n",
        "\n",
        "        // Cleanup\n",
        "        delete[] h_a;\n",
        "        delete[] h_b;\n",
        "        delete[] h_c;\n",
        "        cudaFree(d_a);\n",
        "        cudaFree(d_b);\n",
        "        cudaFree(d_c);\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9hNonWLfcgj",
        "outputId": "cc9f9e83-4e44-4e41-b0ff-e3c26bb17b56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA addition time for size 50: 0.000242\n",
            "CPU multiplication time for size 50: 0.000001\n",
            "Speedup for size 50: 0.00326439\n",
            "\n",
            "CUDA addition time for size 100: 0.000008\n",
            "CPU multiplication time for size 100: 0.000000\n",
            "Speedup for size 100: 0.0443157\n",
            "\n",
            "CUDA addition time for size 500: 0.000006\n",
            "CPU multiplication time for size 500: 0.000002\n",
            "Speedup for size 500: 0.264251\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### task b"
      ],
      "metadata": {
        "id": "bz1I9KximXsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "\n",
        "#include <iostream>\n",
        "#include <chrono>\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "\n",
        "\n",
        "//CUDA kernel\n",
        "__global__ void myKernel(int *result, int N) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < N) {\n",
        "        result[i] = 2 * i;\n",
        "    }\n",
        "}\n",
        "\n",
        "void serialSolution(int *result, int N) {\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        result[i] = 2 * i;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int threads[] = {\n",
        "      1,2,4,8,16\n",
        "    };\n",
        "    for(int i = 0; i < 5; ++i) {\n",
        "      int N = threads[i];\n",
        "    int *result_serial = new int[N];\n",
        "    int *result_cuda;\n",
        "    int size = N * sizeof(int);\n",
        "\n",
        "    cudaMalloc(&result_cuda, size);\n",
        "\n",
        "    auto start = std::chrono::high_resolution_clock::now();\n",
        "    serialSolution(result_serial, N);\n",
        "    auto end = std::chrono::high_resolution_clock::now();\n",
        "    std::chrono::duration<double> serial_duration = end - start;\n",
        "\n",
        "    dim3 blocksPerGrid(1, 1, 1);\n",
        "    dim3 threadsPerBlock( N, 1, 1);\n",
        "\n",
        "    cudaEvent_t start_cuda, stop_cuda;\n",
        "    cudaEventCreate(&start_cuda);\n",
        "    cudaEventCreate(&stop_cuda);\n",
        "\n",
        "    cudaEventRecord(start_cuda);\n",
        "    myKernel<<<blocksPerGrid, threadsPerBlock>>>(result_cuda, N);\n",
        "    cudaEventRecord(stop_cuda);\n",
        "\n",
        "    cudaEventSynchronize(stop_cuda);\n",
        "    float cuda_duration = 0;\n",
        "    cudaEventElapsedTime(&cuda_duration, start_cuda, stop_cuda);\n",
        "\n",
        "    int *result_from_cuda = new int[N];\n",
        "    cudaMemcpy(result_from_cuda, result_cuda, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    double speedup = serial_duration.count() / (cuda_duration / 1000.0);\n",
        "\n",
        "    std::cout << \"For number of threads =\" << N << \" \\n\";\n",
        "    std::cout << \"Serial Execution Time: \" << serial_duration.count() << \" seconds\\n\";\n",
        "    printf(\"CUDA Execution Time using 1 thread blocks & %d threads: %f seconds\\n\", N,\n",
        "           cuda_duration / 1000.0 );\n",
        "    std::cout << \"Speedup: \" << speedup << \"\\n\\n\";\n",
        "\n",
        "\n",
        "    delete[] result_serial;\n",
        "    delete[] result_from_cuda;\n",
        "    cudaFree(result_cuda);\n",
        "    cudaEventDestroy(start_cuda);\n",
        "    cudaEventDestroy(stop_cuda);\n",
        "\n",
        "    }\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RX9KT5ASmUqK",
        "outputId": "f03f4476-526b-41b6-8bac-9a738d88e88f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For number of threads =1 \n",
            "Serial Execution Time: 1.75e-07 seconds\n",
            "CUDA Execution Time using 1 thread blocks & 1 threads: 0.053385 seconds\n",
            "Speedup: 3.27806e-06\n",
            "\n",
            "For number of threads =2 \n",
            "Serial Execution Time: 9e-08 seconds\n",
            "CUDA Execution Time using 1 thread blocks & 2 threads: 0.000030 seconds\n",
            "Speedup: 0.00304713\n",
            "\n",
            "For number of threads =4 \n",
            "Serial Execution Time: 1e-07 seconds\n",
            "CUDA Execution Time using 1 thread blocks & 4 threads: 0.000010 seconds\n",
            "Speedup: 0.00955658\n",
            "\n",
            "For number of threads =8 \n",
            "Serial Execution Time: 9.4e-08 seconds\n",
            "CUDA Execution Time using 1 thread blocks & 8 threads: 0.000009 seconds\n",
            "Speedup: 0.0106047\n",
            "\n",
            "For number of threads =16 \n",
            "Serial Execution Time: 1.25e-07 seconds\n",
            "CUDA Execution Time using 1 thread blocks & 16 threads: 0.000009 seconds\n",
            "Speedup: 0.0135164\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "task c"
      ],
      "metadata": {
        "id": "swbufvlEnCsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#define Width 8\n",
        "__global__ void MatrixMulKernel(int *Md, int *Nd, int *Pd) {\n",
        "int Pvalue = 0;\n",
        "for (int k = 0; k < Width; ++k) {\n",
        "int Melement = Md[threadIdx.y*Width+k];\n",
        "int Nelement = Nd[k*Width+threadIdx.x];\n",
        "Pvalue += Melement * Nelement;\n",
        "}\n",
        "Pd[threadIdx.y*Width+threadIdx.x] = Pvalue;\n",
        "}\n",
        "void MatrixMulOnHost(int *M, int *N, int *P) {\n",
        "for (int i = 0; i < Width; ++i)\n",
        "for (int j = 0; j < Width; ++j) {\n",
        "int sum = 0;\n",
        "for (int k = 0; k < Width; ++k) {\n",
        "int a = M[i * Width + k];\n",
        "int b = N[k * Width + j];\n",
        "sum += a * b;\n",
        "}\n",
        "P[i * Width + j] = sum;\n",
        "}\n",
        "}\n",
        "\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "int size = Width * Width * sizeof(int);\n",
        "int *h_a, *h_b, *h_c, *h_cc;\n",
        "cudaMallocHost((void **) &h_a, size);\n",
        "cudaMallocHost((void **) &h_b, size);\n",
        "cudaMallocHost((void **) &h_c, size);\n",
        "cudaMallocHost((void **) &h_cc, size);\n",
        "int *Md, *Nd, *Pd;\n",
        "for (int i = 0; i < Width; ++i) {\n",
        "for (int j = 0; j < Width; ++j) {\n",
        "h_a[i * Width + j] = i+j;\n",
        "h_b[i * Width + j] = i+j; } }\n",
        "  cudaMalloc(&Md, size);\n",
        "cudaMemcpy(Md, h_a, size, cudaMemcpyHostToDevice);\n",
        "cudaMalloc(&Nd, size);\n",
        "cudaMemcpy(Nd, h_b, size, cudaMemcpyHostToDevice);\n",
        "// Allocate P on the device\n",
        "cudaMalloc(&Pd, size);\n",
        "float gpu_elapsed_time_ms, cpu_elapsed_time_ms;\n",
        "cudaEvent_t start, stop;\n",
        "cudaEventCreate(&start);\n",
        "cudaEventCreate(&stop);\n",
        "\n",
        "// start the CPU version\n",
        "cudaEventRecord(start, 0);\n",
        "MatrixMulOnHost(h_a,h_b,h_c);\n",
        "cudaEventRecord(stop, 0);\n",
        "cudaEventSynchronize(stop);\n",
        "cudaEventElapsedTime(&cpu_elapsed_time_ms, start, stop);\n",
        "\n",
        "printf(\"Time elapsed on CPU: %f ms.\\n\\n\", cpu_elapsed_time_ms);\n",
        "dim3 dimGrid(1, 1);\n",
        "dim3 dimBlock(Width, Width);\n",
        "// Launch the device computation threads!\n",
        "cudaEventRecord(start, 0);\n",
        "MatrixMulKernel<<<dimGrid, dimBlock>>>(Md,Nd,Pd);\n",
        "cudaEventRecord(stop, 0);\n",
        "cudaEventSynchronize(stop);\n",
        "cudaEventElapsedTime(&gpu_elapsed_time_ms, start, stop);\n",
        "cudaMemcpy(h_cc, Pd, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "printf(\"Time elapsed on GPU: %f ms.\\n\\n\", gpu_elapsed_time_ms);\n",
        "cudaFree(Md); cudaFree(Nd); cudaFree (Pd);\n",
        "return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaXMljJ1nEiE",
        "outputId": "50173ae6-c7e2-4d05-b22d-d8bbce2098ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Host results\n",
            "result[0][0]=1\n",
            "result[0][1]=2\n",
            "result[1][0]=2\n",
            "result[1][1]=5\n",
            "Time elapsed on CPU: 0.002336 ms.\n",
            "\n",
            "gpu results\n",
            "result[0][0]=1\n",
            "result[0][1]=2\n",
            "result[1][0]=2\n",
            "result[1][1]=5\n",
            "Time elapsed on GPU: 41.166882 ms.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "task d"
      ],
      "metadata": {
        "id": "m7tc0NQkpSWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "\n",
        "#include <iostream>\n",
        "#include <cuda.h>\n",
        "#include <chrono>\n",
        "\n",
        "#define N 6  // Dimension of the matrix\n",
        "\n",
        "// CUDA kernel for matrix addition\n",
        "__global__ void addMatrixKernel(float* a, float* b, float* c, int n) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < n && col < n) {\n",
        "        int idx = row * n + col;\n",
        "        c[idx] = a[idx] + b[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "// Serial implementation for matrix addition\n",
        "void addMatrixSerial(float* a, float* b, float* c, int n) {\n",
        "    for (int i = 0; i < n; ++i) {\n",
        "        for (int j = 0; j < n; ++j) {\n",
        "            c[i * n + j] = a[i * n + j] + b[i * n + j];\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// Function to generate random float matrix\n",
        "void generateRandomMatrix(float* mat, int n) {\n",
        "    for (int i = 0; i < n * n; ++i) {\n",
        "        mat[i] = static_cast<float>(rand()) / RAND_MAX;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    float* h_a = new float[N * N];\n",
        "    float* h_b = new float[N * N];\n",
        "    float* h_c = new float[N * N];\n",
        "    float *d_a, *d_b, *d_c;\n",
        "\n",
        "    generateRandomMatrix(h_a, N);\n",
        "    generateRandomMatrix(h_b, N);\n",
        "\n",
        "    cudaMalloc(&d_a, N * N * sizeof(float));\n",
        "    cudaMalloc(&d_b, N * N * sizeof(float));\n",
        "    cudaMalloc(&d_c, N * N * sizeof(float));\n",
        "\n",
        "    cudaMemcpy(d_a, h_a, N * N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, N * N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define grid and block dimensions\n",
        "    dim3 dimBlock(16, 16);\n",
        "    dim3 dimGrid((N + dimBlock.x - 1) / dimBlock.x, (N + dimBlock.y - 1) / dimBlock.y);\n",
        "\n",
        "    // Measure time for CUDA matrix addition\n",
        "    cudaEvent_t start, stop;\n",
        "        cudaEventCreate(&stop);\n",
        "\n",
        "    auto start_gpu = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    addMatrixKernel<<<dimGrid, dimBlock>>>(d_a, d_b, d_c, N);\n",
        "\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    auto stop_gpu = std::chrono::high_resolution_clock::now();\n",
        "    std::chrono::duration<double> duration_gpu = stop_gpu - start_gpu;\n",
        "\n",
        "    printf(\"CUDA matrix addition time: %f s \\n\", duration_gpu);\n",
        "\n",
        "    // Measure time for serial matrix addition\n",
        "    auto start_cpu = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    addMatrixSerial(h_a, h_b, h_c, N);\n",
        "\n",
        "    auto stop_cpu = std::chrono::high_resolution_clock::now();\n",
        "    std::chrono::duration<double> duration_cpu = stop_cpu - start_cpu;\n",
        "\n",
        "    printf(\"CPU matrix addition time: %f s \\n\", duration_cpu);\n",
        "\n",
        "    // Compute speedup\n",
        "    float speedup = duration_cpu / duration_gpu;  // converting ms to s\n",
        "    std::cout << \"Speedup: \" << speedup << \"\\n\";\n",
        "\n",
        "    // Cleanup\n",
        "    delete[] h_a;\n",
        "    delete[] h_b;\n",
        "    delete[] h_c;\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4FXU3JGpU6R",
        "outputId": "3bc6d89a-408c-46ca-921f-dee836f18a74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA matrix addition time: 0.000264 s \n",
            "CPU matrix addition time: 0.000001 s \n",
            "Speedup: 0.0023391\n",
            "\n"
          ]
        }
      ]
    }
  ]
}